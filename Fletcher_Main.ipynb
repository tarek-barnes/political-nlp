{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "articles1 = pd.read_csv(\"articles1.csv\")\n",
    "articles2 = pd.read_csv(\"articles2.csv\")\n",
    "articles3 = pd.read_csv(\"articles3.csv\")\n",
    "articles = pd.concat([articles1, articles2, articles3])\n",
    "\n",
    "# This helps to cut down the volume of data I'm working with\n",
    "articles_train, articles_test = train_test_split(articles, test_size=0.5)\n",
    "\n",
    "uci = pd.read_csv(\"uci-news-aggregator.csv\")\n",
    "uci.columns = [k.lower() for k in uci.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Question 1: Do topic modeling on articles - do the topics seem different / are they discussing different things?\n",
    "\n",
    "###  Do topic modeling for each publication segment, compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pub_dict():\n",
    "    pub_dict = {}\n",
    "\n",
    "    for pub in set(articles_train.publication):\n",
    "        pub_df = articles_train[articles_train.publication == pub]\n",
    "        pub_data = zip(pub_df.date, pub_df.title, pub_df.content)\n",
    "        pub_dict[pub] = pub_data\n",
    "        \n",
    "    return pub_dict    \n",
    "\n",
    "\n",
    "def get_topics(model, feature_names, no_top_words):\n",
    "    topics = []\n",
    "    for _, topic in enumerate(model.components_):\n",
    "        topics.append([(feature_names[i], np.round(lsa_cv.components_[_][i], 3)) for i in topic.argsort()[:-no_top_words-1:-1]])\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   min_df = 0.05,\n",
    "                                   max_df = 0.6)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   min_df = 0.05,\n",
    "                                   max_df = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 10\n",
    "lsa_tfidf = TruncatedSVD(n_components=n_comp)\n",
    "lsa_cv = TruncatedSVD(n_components=n_comp)\n",
    "nmf_cv = NMF(n_components=n_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 10\n",
    "pub_dict = get_pub_dict()\n",
    "publications = pub_dict.keys()\n",
    "\n",
    "topic_pub_dict = {}\n",
    "\n",
    "for pub in publications:\n",
    "    pub_articles = [k[2] for k in pub_dict[pub]]\n",
    "    \n",
    "    cv_articles_data = count_vectorizer.fit_transform(pub_articles)\n",
    "    tfidf_articles_data = tfidf_vectorizer.fit_transform(pub_articles)\n",
    "    \n",
    "    lsa_tfidf_articles_data = lsa_tfidf.fit_transform(tfidf_articles_data)\n",
    "    lsa_cv_articles_data = lsa_cv.fit_transform(cv_articles_data)\n",
    "    nmf_cv_articles_data = nmf_cv.fit_transform(cv_articles_data)\n",
    "    \n",
    "    pub_lsa_tfidf = get_topics(lsa_tfidf, tfidf_vectorizer.get_feature_names(), num_top_words)\n",
    "    pub_lsa_cv    = get_topics(lsa_cv,    count_vectorizer.get_feature_names(), num_top_words)\n",
    "    pub_nmf_cv    = get_topics(nmf_cv,    count_vectorizer.get_feature_names(), num_top_words)\n",
    "    \n",
    "    topic_pub_dict[pub] = [pub_lsa_tfidf, pub_lsa_cv, pub_nmf_cv]\n",
    "    \n",
    "    \n",
    "pub_df = pd.DataFrame.from_dict(topic_pub_dict, orient=\"index\")   \n",
    "pub_df.columns = [\"lsa_tfidf\", \"lsa_cv\", \"nmf_cv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_tfidf</th>\n",
       "      <th>lsa_cv</th>\n",
       "      <th>nmf_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York Times</th>\n",
       "      <td>[[(trump, 0.586), (mr trump, 0.366), (ms, 0.10...</td>\n",
       "      <td>[[(trump, 0.586), (mr trump, 0.366), (presiden...</td>\n",
       "      <td>[[(trump, 0.586), (mr trump, 0.366), (presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Post</th>\n",
       "      <td>[[(trump, 0.193), (new, 0.25), (says, 0.185), ...</td>\n",
       "      <td>[[(new, 0.25), (like, 0.236), (just, 0.229), (...</td>\n",
       "      <td>[[(game, 0.09), (season, 0.081), (team, 0.082)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Review</th>\n",
       "      <td>[[(trump, 0.6), (clinton, 0.171), (obama, 0.14...</td>\n",
       "      <td>[[(trump, 0.6), (clinton, 0.171), (president, ...</td>\n",
       "      <td>[[(trump, 0.6), (donald, 0.088), (donald trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>[[(trump, 0.422), (percent, 0.217), (billion, ...</td>\n",
       "      <td>[[(trump, 0.422), (percent, 0.217), (president...</td>\n",
       "      <td>[[(trump, 0.422), (president, 0.188), (campaig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPR</th>\n",
       "      <td>[[(trump, 0.361), (said, 0.322), (president, 0...</td>\n",
       "      <td>[[(trump, 0.361), (said, 0.322), (president, 0...</td>\n",
       "      <td>[[(think, 0.144), (know, 0.126), (going, 0.135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>[[(trump, 0.414), (said, 0.393), (president, 0...</td>\n",
       "      <td>[[(trump, 0.414), (said, 0.393), (people, 0.26...</td>\n",
       "      <td>[[(people, 0.265), (think, 0.17), (like, 0.213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Points Memo</th>\n",
       "      <td>[[(trump, 0.692), (president, 0.206), (house, ...</td>\n",
       "      <td>[[(trump, 0.692), (president, 0.206), (people,...</td>\n",
       "      <td>[[(trump, 0.692), (donald, 0.087), (donald tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>[[(trump, 0.609), (president, 0.186), (people,...</td>\n",
       "      <td>[[(trump, 0.609), (people, 0.197), (president,...</td>\n",
       "      <td>[[(trump, 0.609), (campaign, 0.11), (donald, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buzzfeed News</th>\n",
       "      <td>[[(trump, 0.212), (like, 0.253), (buzzfeed, 0....</td>\n",
       "      <td>[[(like, 0.253), (trump, 0.212), (just, 0.196)...</td>\n",
       "      <td>[[(like, 0.253), (just, 0.196), (says, 0.093),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guardian</th>\n",
       "      <td>[[(trump, 0.415), (like, 0.192), (new, 0.176),...</td>\n",
       "      <td>[[(trump, 0.415), (like, 0.192), (just, 0.179)...</td>\n",
       "      <td>[[(like, 0.192), (just, 0.179), (don, 0.114), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>[[(trump, 0.601), (clinton, 0.117), (president...</td>\n",
       "      <td>[[(trump, 0.601), (president, 0.174), (know, 0...</td>\n",
       "      <td>[[(trump, 0.601), (donald, 0.079), (donald tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vox</th>\n",
       "      <td>[[(trump, 0.625), (clinton, 0.145), (president...</td>\n",
       "      <td>[[(trump, 0.625), (clinton, 0.145), (president...</td>\n",
       "      <td>[[(trump, 0.625), (campaign, 0.1), (donald, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>[[(trump, 0.633), (clinton, 0.242), (president...</td>\n",
       "      <td>[[(trump, 0.633), (says, 0.457), (clinton, 0.2...</td>\n",
       "      <td>[[(trump, 0.633), (donald, 0.094), (donald tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>[[(trump, 0.548), (clinton, 0.417), (campaign,...</td>\n",
       "      <td>[[(trump, 0.548), (clinton, 0.417), (percent, ...</td>\n",
       "      <td>[[(trump, 0.548), (campaign, 0.146), (donald, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlantic</th>\n",
       "      <td>[[(trump, 0.838), (president, 0.244), (clinton...</td>\n",
       "      <td>[[(trump, 0.838), (president, 0.244), (busines...</td>\n",
       "      <td>[[(trump, 0.838), (president, 0.244), (organiz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             lsa_tfidf  \\\n",
       "New York Times       [[(trump, 0.586), (mr trump, 0.366), (ms, 0.10...   \n",
       "New York Post        [[(trump, 0.193), (new, 0.25), (says, 0.185), ...   \n",
       "National Review      [[(trump, 0.6), (clinton, 0.171), (obama, 0.14...   \n",
       "Reuters              [[(trump, 0.422), (percent, 0.217), (billion, ...   \n",
       "NPR                  [[(trump, 0.361), (said, 0.322), (president, 0...   \n",
       "Business Insider     [[(trump, 0.414), (said, 0.393), (president, 0...   \n",
       "Talking Points Memo  [[(trump, 0.692), (president, 0.206), (house, ...   \n",
       "CNN                  [[(trump, 0.609), (president, 0.186), (people,...   \n",
       "Buzzfeed News        [[(trump, 0.212), (like, 0.253), (buzzfeed, 0....   \n",
       "Guardian             [[(trump, 0.415), (like, 0.192), (new, 0.176),...   \n",
       "Washington Post      [[(trump, 0.601), (clinton, 0.117), (president...   \n",
       "Vox                  [[(trump, 0.625), (clinton, 0.145), (president...   \n",
       "Breitbart            [[(trump, 0.633), (clinton, 0.242), (president...   \n",
       "Fox News             [[(trump, 0.548), (clinton, 0.417), (campaign,...   \n",
       "Atlantic             [[(trump, 0.838), (president, 0.244), (clinton...   \n",
       "\n",
       "                                                                lsa_cv  \\\n",
       "New York Times       [[(trump, 0.586), (mr trump, 0.366), (presiden...   \n",
       "New York Post        [[(new, 0.25), (like, 0.236), (just, 0.229), (...   \n",
       "National Review      [[(trump, 0.6), (clinton, 0.171), (president, ...   \n",
       "Reuters              [[(trump, 0.422), (percent, 0.217), (president...   \n",
       "NPR                  [[(trump, 0.361), (said, 0.322), (president, 0...   \n",
       "Business Insider     [[(trump, 0.414), (said, 0.393), (people, 0.26...   \n",
       "Talking Points Memo  [[(trump, 0.692), (president, 0.206), (people,...   \n",
       "CNN                  [[(trump, 0.609), (people, 0.197), (president,...   \n",
       "Buzzfeed News        [[(like, 0.253), (trump, 0.212), (just, 0.196)...   \n",
       "Guardian             [[(trump, 0.415), (like, 0.192), (just, 0.179)...   \n",
       "Washington Post      [[(trump, 0.601), (president, 0.174), (know, 0...   \n",
       "Vox                  [[(trump, 0.625), (clinton, 0.145), (president...   \n",
       "Breitbart            [[(trump, 0.633), (says, 0.457), (clinton, 0.2...   \n",
       "Fox News             [[(trump, 0.548), (clinton, 0.417), (percent, ...   \n",
       "Atlantic             [[(trump, 0.838), (president, 0.244), (busines...   \n",
       "\n",
       "                                                                nmf_cv  \n",
       "New York Times       [[(trump, 0.586), (mr trump, 0.366), (presiden...  \n",
       "New York Post        [[(game, 0.09), (season, 0.081), (team, 0.082)...  \n",
       "National Review      [[(trump, 0.6), (donald, 0.088), (donald trump...  \n",
       "Reuters              [[(trump, 0.422), (president, 0.188), (campaig...  \n",
       "NPR                  [[(think, 0.144), (know, 0.126), (going, 0.135...  \n",
       "Business Insider     [[(people, 0.265), (think, 0.17), (like, 0.213...  \n",
       "Talking Points Memo  [[(trump, 0.692), (donald, 0.087), (donald tru...  \n",
       "CNN                  [[(trump, 0.609), (campaign, 0.11), (donald, 0...  \n",
       "Buzzfeed News        [[(like, 0.253), (just, 0.196), (says, 0.093),...  \n",
       "Guardian             [[(like, 0.192), (just, 0.179), (don, 0.114), ...  \n",
       "Washington Post      [[(trump, 0.601), (donald, 0.079), (donald tru...  \n",
       "Vox                  [[(trump, 0.625), (campaign, 0.1), (donald, 0....  \n",
       "Breitbart            [[(trump, 0.633), (donald, 0.094), (donald tru...  \n",
       "Fox News             [[(trump, 0.548), (campaign, 0.146), (donald, ...  \n",
       "Atlantic             [[(trump, 0.838), (president, 0.244), (organiz...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('trump', 0.838),\n",
       "  ('president', 0.244),\n",
       "  ('business', 0.088),\n",
       "  ('organization', 0.087),\n",
       "  ('election', 0.079),\n",
       "  ('clinton', 0.068),\n",
       "  ('donald', 0.068),\n",
       "  ('campaign', 0.067),\n",
       "  ('company', 0.062),\n",
       "  ('donald trump', 0.06)],\n",
       " [('think', 0.167),\n",
       "  ('way', 0.152),\n",
       "  ('don', 0.151),\n",
       "  ('clinton', 0.136),\n",
       "  ('know', 0.133),\n",
       "  ('reader', 0.126),\n",
       "  ('did', 0.123),\n",
       "  ('work', 0.119),\n",
       "  ('ve', 0.117),\n",
       "  ('make', 0.113)],\n",
       " [('clinton', 0.346),\n",
       "  ('trump', 0.193),\n",
       "  ('republican', 0.192),\n",
       "  ('hillary', 0.174),\n",
       "  ('donald', 0.168),\n",
       "  ('donald trump', 0.165),\n",
       "  ('vote', 0.16),\n",
       "  ('hillary clinton', 0.15),\n",
       "  ('nominee', 0.147),\n",
       "  ('gop', 0.097)],\n",
       " [('reader', 0.231),\n",
       "  ('think', 0.141),\n",
       "  ('know', 0.098),\n",
       "  ('trump', 0.098),\n",
       "  ('really', 0.088),\n",
       "  ('way', 0.087),\n",
       "  ('don', 0.081),\n",
       "  ('ve', 0.08),\n",
       "  ('song', 0.073),\n",
       "  ('things', 0.071)],\n",
       " [('obama', 0.232),\n",
       "  ('states', 0.183),\n",
       "  ('president', 0.18),\n",
       "  ('clinton', 0.166),\n",
       "  ('war', 0.164),\n",
       "  ('united', 0.156),\n",
       "  ('american', 0.154),\n",
       "  ('world', 0.148),\n",
       "  ('united states', 0.137),\n",
       "  ('america', 0.134)],\n",
       " [('clinton', 0.354),\n",
       "  ('women', 0.331),\n",
       "  ('men', 0.116),\n",
       "  ('told', 0.113),\n",
       "  ('president', 0.111),\n",
       "  ('state', 0.105),\n",
       "  ('organization', 0.095),\n",
       "  ('business', 0.095),\n",
       "  ('hillary', 0.093),\n",
       "  ('woman', 0.09)],\n",
       " [('clinton', 0.498),\n",
       "  ('reader', 0.23),\n",
       "  ('students', 0.197),\n",
       "  ('election', 0.174),\n",
       "  ('president', 0.155),\n",
       "  ('obama', 0.12),\n",
       "  ('emails', 0.118),\n",
       "  ('school', 0.104),\n",
       "  ('college', 0.089),\n",
       "  ('fbi', 0.077)],\n",
       " [('women', 0.72),\n",
       "  ('men', 0.187),\n",
       "  ('students', 0.139),\n",
       "  ('percent', 0.135),\n",
       "  ('woman', 0.112),\n",
       "  ('female', 0.095),\n",
       "  ('gender', 0.079),\n",
       "  ('america', 0.073),\n",
       "  ('male', 0.07),\n",
       "  ('american', 0.067)],\n",
       " [('clinton', 0.216),\n",
       "  ('world', 0.197),\n",
       "  ('war', 0.149),\n",
       "  ('hillary', 0.135),\n",
       "  ('students', 0.122),\n",
       "  ('china', 0.12),\n",
       "  ('hillary clinton', 0.116),\n",
       "  ('think', 0.111),\n",
       "  ('president', 0.109),\n",
       "  ('says', 0.1)],\n",
       " [('think', 0.165),\n",
       "  ('work', 0.119),\n",
       "  ('obama', 0.112),\n",
       "  ('state', 0.106),\n",
       "  ('don', 0.102),\n",
       "  ('says', 0.092),\n",
       "  ('vote', 0.089),\n",
       "  ('really', 0.089),\n",
       "  ('children', 0.077),\n",
       "  ('going', 0.076)]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_pub_dict[\"Atlantic\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Could / should I also compare with topic modeling for entire corpus?\n",
    "\n",
    "###  Can I make a bubble plot for each publication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(list_of_lists):\n",
    "    return [k for sublist in list_of_lists for k in sublist]\n",
    "\n",
    "\n",
    "def get_distinct_topics(model):\n",
    "    distinct_topics = {}\n",
    "    pub_topics = list(pub_df[model].items())\n",
    "    n = len(pub_topics)\n",
    "    for k in range(n):\n",
    "        publication = pub_topics[k][0]\n",
    "        flat_topics = flatten(pub_topics[k][1])\n",
    "        unique_flat_topics = set(flat_topics)\n",
    "        distinct_topics[publication] = unique_flat_topics\n",
    "    return distinct_topics    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distinct_topics('lsa_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Question 2: Are average sentence length or average article length indicative of political opinion?\n",
    "\n",
    "###  Calculate average sentence count / article\n",
    "###  Calculate average words / article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_sentences(article):\n",
    "    stoppers = [\".\", \"!\", \"?\"]\n",
    "    num_sentences = 0\n",
    "    for k in stoppers:\n",
    "        num_sentences += article.count(k)\n",
    "    return num_sentences\n",
    "        \n",
    "        \n",
    "def get_num_words(article):\n",
    "    return len(article.split(\" \"))\n",
    "\n",
    "\n",
    "def get_avg_word_length(article):\n",
    "    fillers = list(\".,!?:'-()/\")\n",
    "    for k in fillers:\n",
    "        article = article.replace(k, \"\")\n",
    "    article = article.replace('\"', '')    \n",
    "    all_words = article.split(\" \")\n",
    "    avg_word_length = np.average([len(k) for k in all_words])\n",
    "    avg_word_length = np.round(avg_word_length, 1)\n",
    "    return avg_word_length\n",
    "    \n",
    "    \n",
    "def get_adjective_count(article):\n",
    "    data = nltk.word_tokenize(article)\n",
    "    categories = nltk.pos_tag(data)\n",
    "    return len([k[1] for k in example if \"JJ\" in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_words_sentences_dict = {}\n",
    "pub_dict = get_pub_dict()\n",
    "\n",
    "for pub in publications:\n",
    "    pub_articles = [k[2] for k in pub_dict[pub]]\n",
    "    \n",
    "    avg_sentences = np.average([get_num_sentences(k) for k in pub_articles])\n",
    "    avg_sentences = np.round(avg_sentences, 1)\n",
    "    \n",
    "    avg_words = np.average([get_num_words(k) for k in pub_articles])\n",
    "    avg_words = np.round(avg_words, 1)\n",
    "    \n",
    "    avg_word_length = np.average([get_avg_word_length(k) for k in pub_articles])\n",
    "    avg_word_length = np.round(avg_word_length, 1)\n",
    "    \n",
    "    avg_words_sentences_dict[pub] = (avg_sentences, avg_words, avg_word_length)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reuters': (37.0, 694.1, 4.7),\n",
       " 'Guardian': (45.1, 936.9, 4.6),\n",
       " 'Vox': (65.5, 1445.3, 4.4),\n",
       " 'Washington Post': (59.5, 1081.1, 4.5),\n",
       " 'Fox News': (30.4, 539.4, 4.6),\n",
       " 'New York Times': (76.0, 1192.9, 4.6),\n",
       " 'CNN': (39.5, 743.9, 4.6),\n",
       " 'NPR': (46.8, 799.5, 4.6),\n",
       " 'National Review': (50.2, 977.2, 4.7),\n",
       " 'New York Post': (25.0, 464.0, 4.4),\n",
       " 'Buzzfeed News': (44.7, 917.5, 4.6),\n",
       " 'Atlantic': (69.2, 1370.8, 4.6),\n",
       " 'Talking Points Memo': (21.0, 377.4, 4.7),\n",
       " 'Breitbart': (27.2, 525.9, 4.7),\n",
       " 'Business Insider': (23.8, 533.4, 3.9)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_words_sentences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average adjectives / article\n",
    "\n",
    "###   Cluster!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
